{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mateo1/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /home/mateo1/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "I9z79By8L9dy"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>PUBLISHER</th>\n",
       "      <th>BOOKTITLE</th>\n",
       "      <th>CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>A Systematic Survey of Text Worlds as Embodied...</td>\n",
       "      <td>Text Worlds are virtual environments for embod...</td>\n",
       "      <td>Jansen, Peter</td>\n",
       "      <td>Association for Computational Linguistics</td>\n",
       "      <td>Proceedings of the 3rd Wordplay: When Language...</td>\n",
       "      <td>INPROCEEDINGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>A Minimal Computational Improviser Based on Or...</td>\n",
       "      <td>A prototype system for playing a minimal impro...</td>\n",
       "      <td>Montfort, Nick  and</td>\n",
       "      <td>Association for Computational Linguistics</td>\n",
       "      <td>Proceedings of the 3rd Wordplay: When Language...</td>\n",
       "      <td>INPROCEEDINGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>Craft an Iron Sword: Dynamically Generating In...</td>\n",
       "      <td>Non-Player Characters (NPCs) significantly enh...</td>\n",
       "      <td>Volum, Ryan  and</td>\n",
       "      <td>Association for Computational Linguistics</td>\n",
       "      <td>Proceedings of the 3rd Wordplay: When Language...</td>\n",
       "      <td>INPROCEEDINGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>A Sequence Modelling Approach to Question Answ...</td>\n",
       "      <td>Interactive Question Answering (IQA) requires ...</td>\n",
       "      <td>Furman, Gregory  and</td>\n",
       "      <td>Association for Computational Linguistics</td>\n",
       "      <td>Proceedings of the 3rd Wordplay: When Language...</td>\n",
       "      <td>INPROCEEDINGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>Automatic Exploration of Textual Environments ...</td>\n",
       "      <td>The purpose of this extended abstract is to di...</td>\n",
       "      <td>Teodorescu, Laetitia  and</td>\n",
       "      <td>Association for Computational Linguistics</td>\n",
       "      <td>Proceedings of the 3rd Wordplay: When Language...</td>\n",
       "      <td>INPROCEEDINGS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR                                              TITLE  \\\n",
       "0  2022  A Systematic Survey of Text Worlds as Embodied...   \n",
       "1  2022  A Minimal Computational Improviser Based on Or...   \n",
       "2  2022  Craft an Iron Sword: Dynamically Generating In...   \n",
       "3  2022  A Sequence Modelling Approach to Question Answ...   \n",
       "4  2022  Automatic Exploration of Textual Environments ...   \n",
       "\n",
       "                                            ABSTRACT  \\\n",
       "0  Text Worlds are virtual environments for embod...   \n",
       "1  A prototype system for playing a minimal impro...   \n",
       "2  Non-Player Characters (NPCs) significantly enh...   \n",
       "3  Interactive Question Answering (IQA) requires ...   \n",
       "4  The purpose of this extended abstract is to di...   \n",
       "\n",
       "                      AUTHOR                                  PUBLISHER  \\\n",
       "0              Jansen, Peter  Association for Computational Linguistics   \n",
       "1        Montfort, Nick  and  Association for Computational Linguistics   \n",
       "2           Volum, Ryan  and  Association for Computational Linguistics   \n",
       "3       Furman, Gregory  and  Association for Computational Linguistics   \n",
       "4  Teodorescu, Laetitia  and  Association for Computational Linguistics   \n",
       "\n",
       "                                           BOOKTITLE       CATEGORY  \n",
       "0  Proceedings of the 3rd Wordplay: When Language...  INPROCEEDINGS  \n",
       "1  Proceedings of the 3rd Wordplay: When Language...  INPROCEEDINGS  \n",
       "2  Proceedings of the 3rd Wordplay: When Language...  INPROCEEDINGS  \n",
       "3  Proceedings of the 3rd Wordplay: When Language...  INPROCEEDINGS  \n",
       "4  Proceedings of the 3rd Wordplay: When Language...  INPROCEEDINGS  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/ACL_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a_p9lzhmOpq5",
    "outputId": "0de91ac3-6379-44b8-de41-21fad7ae0671"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32352 entries, 0 to 32351\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   YEAR       32352 non-null  int64 \n",
      " 1   TITLE      32352 non-null  object\n",
      " 2   ABSTRACT   32246 non-null  object\n",
      " 3   PUBLISHER  32352 non-null  object\n",
      " 4   BOOKTITLE  32352 non-null  object\n",
      " 5   CATEGORY   32352 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020    6574\n",
       "2021    5774\n",
       "2019    4315\n",
       "2018    3363\n",
       "2022    3054\n",
       "2017    2495\n",
       "2016    1778\n",
       "2010     832\n",
       "2014     819\n",
       "2012     762\n",
       "2008     735\n",
       "2006     622\n",
       "2004     201\n",
       "2011     117\n",
       "2015     107\n",
       "2009     104\n",
       "2002      88\n",
       "2007      88\n",
       "2005      88\n",
       "2000      79\n",
       "2003      64\n",
       "2001      61\n",
       "1998      51\n",
       "1989      47\n",
       "1993      43\n",
       "1995      33\n",
       "1997      31\n",
       "1991      27\n",
       "Name: YEAR, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.YEAR.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Association for Computational Linguistics                                                 21004\n",
       "European Language Resources Association (ELRA)                                             4147\n",
       "ATALA                                                                                      1375\n",
       "European Language Resources Association                                                    1104\n",
       "The COLING 2016 Organizing Committee                                                        739\n",
       "International Committee on Computational Linguistics                                        654\n",
       "INCOMA Ltd.                                                                                 573\n",
       "Association for Machine Translation in the Americas                                         384\n",
       "International Committee for Computational Linguistics                                       307\n",
       "Asian Federation of Natural Language Processing                                             253\n",
       "Chinese Information Processing Society of China                                             217\n",
       "Global Wordnet Association                                                                  200\n",
       "AFCP - ATALA                                                                                169\n",
       "ATALA et AFCP                                                                               161\n",
       "Springer                                                                                    146\n",
       "European Association for Machine Translation                                                140\n",
       "NLP Association of India (NLPAI)                                                            107\n",
       "Australasian Language Technology Association                                                 73\n",
       "Link{\\\"o}ping University Electronic Press                                                    56\n",
       "Link{\\\"o}ping University Electronic Press, Sweden                                            54\n",
       "European Language Resources association                                                      52\n",
       "The Association for Computational Linguistics and Chinese Language Processing (ACLCLP)       51\n",
       "CSLI Publications                                                                            49\n",
       "International Committee on Computational Linguistics (ICCL)                                  48\n",
       "Carnegy Mellon University                                                                    47\n",
       "International Workshop on Spoken Language Translation                                        46\n",
       "COLING                                                                                       36\n",
       "International Conference on Spoken Language Translation                                      28\n",
       "NLP Association of India                                                                     28\n",
       "European Language Resource Association                                                       18\n",
       "Incoma Ltd., Shoumen, Bulgaria                                                               18\n",
       "Springer Berlin Heidelberg                                                                   16\n",
       "INCOMA Inc.                                                                                  15\n",
       "The Association for Machine Translation in the Americas                                      13\n",
       "European Language Ressources Association                                                      9\n",
       "Association for Computational Linguistics, Shoumen, Bulgaria                                  8\n",
       "The European Language Resources Association (ELRA)                                            7\n",
       "Name: PUBLISHER, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.PUBLISHER.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INPROCEEDINGS    32352\n",
       "Name: CATEGORY, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.CATEGORY.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Text Worlds are virtual environments for embodied agents that, unlike 2D or 3D environments, are rendered exclusively using textual descriptions. These environments offer an alternative to higher-fidelity 3D environments due to their low barrier to entry, providing the ability to study semantics, compositional inference, and other high-level tasks with rich action spaces while controlling for perceptual input. This systematic survey outlines recent developments in tooling, environments, and agent modeling for Text Worlds, while examining recent trends in knowledge graphs, common sense reasoning, transfer learning of Text World performance to higher-fidelity environments, as well as near-term development targets that, once achieved, make Text Worlds an attractive general research paradigm for natural language processing.',\n",
       "       \"A prototype system for playing a minimal improvisational game with one or more human or computer players is discussed. The game, Chain Reaction, has players collectively build a chain of word pairs or solid compounds. With a basis in oral culture, it emphasizes memory and rapid improvisation. Chains are only locally coherent, so absurdity and humor increases during play. While it is trivial to develop a computer player using textual corpora and literature-culture concepts, our approach is unique in that we have grounded our work in the principles of oral culture according to Walter Ong, an early scholar of orature. We show how a simple computer model can be designed to embody many aspects of oral poetics as theorized by Ong, suggesting design directions for other work in oral improvisation and poetics. The opportunities for own our system{'}s further development include creating culturally specific automated players and situating play in different temporal, physical, and social contexts.\",\n",
       "       \"Non-Player Characters (NPCs) significantly enhance the player experience in many games. Historically, players{'} interactions with NPCs have tended to be highly scripted, to be limited to natural language responses to be selected by the player, and to not involve dynamic change in game state. In this work, we demonstrate that use of a few example conversational prompts can power a conversational agent to generate both natural language and novel code. This approach can permit development of NPCs with which players can have grounded conversations that are free-form and less repetitive. We demonstrate our approach using OpenAI Codex (GPT-3 finetuned on GitHub), with Minecraft game development as our test bed. We show that with a few example prompts, a Codex-based agent can generate novel code, hold multi-turn conversations and answer questions about structured data. We evaluate this application using experienced gamers in a Minecraft realm and provide analysis of failure cases and suggest possible directions for solutions.\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.ABSTRACT[:3].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "a-Gmt9VqQVU-"
   },
   "outputs": [],
   "source": [
    "# En este caso particular no hace falta limpiar los textos\n",
    "def clean_text(text):\n",
    "    if isinstance(text, pd.Series):\n",
    "        return text.str.strip().str.lower().values\n",
    "    elif isinstance(text, str):\n",
    "        return text.strip().lower()\n",
    "\n",
    "def tokenizer(text):\n",
    "    #return [w for w in word_tokenize(text) if w.isalpha()] # si solo nos interesan palabras\n",
    "    return word_tokenize(str(text))\n",
    "    # if isinstance(text, str):\n",
    "    #     return word_tokenize(text)\n",
    "    # else:\n",
    "    #     return text.apply(word_tokenize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text worlds are virtual environments for embodied agents that, unlike 2d or 3d environments, are rendered exclusively using textual descriptions. these environments offer an alternative to higher-fidelity 3d environments due to their low barrier to entry, providing the ability to study semantics, compositional inference, and other high-level tasks with rich action spaces while controlling for perceptual input. this systematic survey outlines recent developments in tooling, environments, and agent modeling for text worlds, while examining recent trends in knowledge graphs, common sense reasoning, transfer learning of text world performance to higher-fidelity environments, as well as near-term development targets that, once achieved, make text worlds an attractive general research paradigm for natural language processing.'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(data.ABSTRACT[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " \"'text\",\n",
       " 'worlds',\n",
       " 'are',\n",
       " 'virtual',\n",
       " 'environments',\n",
       " 'for',\n",
       " 'embodied',\n",
       " 'agents',\n",
       " 'that']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word_tokenize(clean_text(data.ABSTRACT))\n",
    "tokenizer(clean_text(data.ABSTRACT))[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print( type( clean_text( data.ABSTRACT[0]) ))\n",
    "print( type(clean_text( data.ABSTRACT[:1]) ) )\n",
    "print( type(clean_text( data.ABSTRACT) ) )\n",
    "\n",
    "# tokenizer(clean_text(data.ABSTRACT[:1] ))#[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Normalizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('worlds', 'world'),\n",
       " ('are', 'are'),\n",
       " ('virtual', 'virtual'),\n",
       " ('environments', 'environ'),\n",
       " ('for', 'for'),\n",
       " ('embodied', 'embodi'),\n",
       " ('agents', 'agent'),\n",
       " ('that', 'that'),\n",
       " ('unlike', 'unlik'),\n",
       " ('or', 'or')]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "\n",
    "[(w,stemmer.stem(w)) for w in tokenizer(clean_text(data.ABSTRACT)) if w.isalpha()][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text worlds are virtual environments for embodied agents that, unlike 2d or 3d environments, are rendered exclusively using textual descriptions. these environments offer an alternative to higher-fidelity 3d environments due to their low barrier to entry, providing the ability to study semantics, compositional inference, and other high-level tasks with rich action spaces while controlling for perceptual input. this systematic survey outlines recent developments in tooling, environments, and agent modeling for text worlds, while examining recent trends in knowledge graphs, common sense reasoning, transfer learning of text world performance to higher-fidelity environments, as well as near-term development targets that, once achieved, make text worlds an attractive general research paradigm for natural language processing.'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(clean_text(data.ABSTRACT[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text worlds are virtual environments for embodied agents that, unlike 2d or 3d environments, are rendered exclusively using textual descriptions. these environments offer an alternative to higher-fidelity 3d environments due to their low barrier to entry, providing the ability to study semantics, compositional inference, and other high-level tasks with rich action spaces while controlling for perceptual input. this systematic survey outlines recent developments in tooling, environments, and agent modeling for text worlds, while examining recent trends in knowledge graphs, common sense reasoning, transfer learning of text world performance to higher-fidelity environments, as well as near-term development targets that, once achieved, make text worlds an attractive general research paradigm for natural language processing.'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(data.ABSTRACT[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stoplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoplist = stopwords.words(\"english\")\n",
    "stoplist[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doing',\n",
       " 'but',\n",
       " 'so',\n",
       " 'until',\n",
       " 'yours',\n",
       " 'from',\n",
       " 'again',\n",
       " 'mustn',\n",
       " 'will',\n",
       " 'against']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizo el stoplist con el mismo tokenizar que voy a usar en el corpus\n",
    "stoplist_tokenized = []\n",
    "for w in stoplist:\n",
    "    stoplist_tokenized = stoplist_tokenized + tokenizer(w)\n",
    "    \n",
    "# Armo una lista sin repeticiones\n",
    "stoplist_tokenized = list(set(stoplist_tokenized))\n",
    "\n",
    "stoplist_tokenized[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('T', 't'),\n",
       " ('e', 'e'),\n",
       " ('x', 'x'),\n",
       " ('t', 't'),\n",
       " ('W', 'w'),\n",
       " ('o', 'o'),\n",
       " ('r', 'r'),\n",
       " ('l', 'l'),\n",
       " ('d', 'd'),\n",
       " ('s', 's')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(w,stemmer.stem(w)) for w in clean_text(data.ABSTRACT.iloc[0]) if w.isalpha()][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraigo features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<32352x19342 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2334801 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer(preprocessor=clean_text,\n",
    "                             tokenizer=tokenizer,\n",
    "                             min_df=5,\n",
    "                             stop_words=stoplist_tokenized)\n",
    "\n",
    "data_clean = count_vect.fit_transform(data.ABSTRACT.values.astype('U')) # cuenta frecuencia de tokens y define el diccionario\n",
    "# X_test = count_vect.transform(X_test_text) # cuenta frecuencia de tokens existentes en el diccionario\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consultar sobre diferencia entre fit_transform y transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamaño de la matriz: 625752384\n",
      "porcentaje de elementos distintos de cero: % 0.37\n"
     ]
    }
   ],
   "source": [
    "print(\"tamaño de la matriz:\",32352*19342)\n",
    "print(\"porcentaje de elementos distintos de cero: %\",round(100*2334801/(32352*19342),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mateo1/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " \"''\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " '+0.8',\n",
       " '+0.9',\n",
       " '+1',\n",
       " '+1.0',\n",
       " '+1.2',\n",
       " '+1.3',\n",
       " '+1.7',\n",
       " '+2.1',\n",
       " '+5']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.get_feature_names()[:20]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
