{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kpmC6Rm_m3B",
        "outputId": "47c73557-54a2-4e52-ec47-7962d523c861"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# !pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9z79By8L9dy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "import re\n",
        "\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXpyxS7x_m3H"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "Ehp6FKi7_m3K",
        "outputId": "ed24cec1-c121-41e8-d5e1-5a70eeae3a64"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9a6af54b-53c4-4343-9601-780c2d9f9337\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>ABSTRACT</th>\n",
              "      <th>AUTHOR</th>\n",
              "      <th>PUBLISHER</th>\n",
              "      <th>BOOKTITLE</th>\n",
              "      <th>CATEGORY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022</td>\n",
              "      <td>A Systematic Survey of Text Worlds as Embodied...</td>\n",
              "      <td>Text Worlds are virtual environments for embod...</td>\n",
              "      <td>Jansen, Peter</td>\n",
              "      <td>Association for Computational Linguistics</td>\n",
              "      <td>Proceedings of the 3rd Wordplay: When Language...</td>\n",
              "      <td>INPROCEEDINGS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022</td>\n",
              "      <td>A Minimal Computational Improviser Based on Or...</td>\n",
              "      <td>A prototype system for playing a minimal impro...</td>\n",
              "      <td>Montfort, Nick  and</td>\n",
              "      <td>Association for Computational Linguistics</td>\n",
              "      <td>Proceedings of the 3rd Wordplay: When Language...</td>\n",
              "      <td>INPROCEEDINGS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022</td>\n",
              "      <td>Craft an Iron Sword: Dynamically Generating In...</td>\n",
              "      <td>Non-Player Characters (NPCs) significantly enh...</td>\n",
              "      <td>Volum, Ryan  and</td>\n",
              "      <td>Association for Computational Linguistics</td>\n",
              "      <td>Proceedings of the 3rd Wordplay: When Language...</td>\n",
              "      <td>INPROCEEDINGS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022</td>\n",
              "      <td>A Sequence Modelling Approach to Question Answ...</td>\n",
              "      <td>Interactive Question Answering (IQA) requires ...</td>\n",
              "      <td>Furman, Gregory  and</td>\n",
              "      <td>Association for Computational Linguistics</td>\n",
              "      <td>Proceedings of the 3rd Wordplay: When Language...</td>\n",
              "      <td>INPROCEEDINGS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022</td>\n",
              "      <td>Automatic Exploration of Textual Environments ...</td>\n",
              "      <td>The purpose of this extended abstract is to di...</td>\n",
              "      <td>Teodorescu, Laetitia  and</td>\n",
              "      <td>Association for Computational Linguistics</td>\n",
              "      <td>Proceedings of the 3rd Wordplay: When Language...</td>\n",
              "      <td>INPROCEEDINGS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a6af54b-53c4-4343-9601-780c2d9f9337')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a6af54b-53c4-4343-9601-780c2d9f9337 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a6af54b-53c4-4343-9601-780c2d9f9337');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   YEAR                                              TITLE  \\\n",
              "0  2022  A Systematic Survey of Text Worlds as Embodied...   \n",
              "1  2022  A Minimal Computational Improviser Based on Or...   \n",
              "2  2022  Craft an Iron Sword: Dynamically Generating In...   \n",
              "3  2022  A Sequence Modelling Approach to Question Answ...   \n",
              "4  2022  Automatic Exploration of Textual Environments ...   \n",
              "\n",
              "                                            ABSTRACT  \\\n",
              "0  Text Worlds are virtual environments for embod...   \n",
              "1  A prototype system for playing a minimal impro...   \n",
              "2  Non-Player Characters (NPCs) significantly enh...   \n",
              "3  Interactive Question Answering (IQA) requires ...   \n",
              "4  The purpose of this extended abstract is to di...   \n",
              "\n",
              "                      AUTHOR                                  PUBLISHER  \\\n",
              "0              Jansen, Peter  Association for Computational Linguistics   \n",
              "1        Montfort, Nick  and  Association for Computational Linguistics   \n",
              "2           Volum, Ryan  and  Association for Computational Linguistics   \n",
              "3       Furman, Gregory  and  Association for Computational Linguistics   \n",
              "4  Teodorescu, Laetitia  and  Association for Computational Linguistics   \n",
              "\n",
              "                                           BOOKTITLE       CATEGORY  \n",
              "0  Proceedings of the 3rd Wordplay: When Language...  INPROCEEDINGS  \n",
              "1  Proceedings of the 3rd Wordplay: When Language...  INPROCEEDINGS  \n",
              "2  Proceedings of the 3rd Wordplay: When Language...  INPROCEEDINGS  \n",
              "3  Proceedings of the 3rd Wordplay: When Language...  INPROCEEDINGS  \n",
              "4  Proceedings of the 3rd Wordplay: When Language...  INPROCEEDINGS  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#data = pd.read_csv(\"data/ACL_data.csv\")\n",
        "data = pd.read_csv(\"ACL_data.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_p9lzhmOpq5",
        "outputId": "8a32052b-c701-47c5-cc90-8797216e6e8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 33811 entries, 0 to 33810\n",
            "Data columns (total 7 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   YEAR       33811 non-null  int64 \n",
            " 1   TITLE      33811 non-null  object\n",
            " 2   ABSTRACT   33703 non-null  object\n",
            " 3   AUTHOR     33768 non-null  object\n",
            " 4   PUBLISHER  32951 non-null  object\n",
            " 5   BOOKTITLE  33156 non-null  object\n",
            " 6   CATEGORY   33811 non-null  object\n",
            "dtypes: int64(1), object(6)\n",
            "memory usage: 1.8+ MB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS9JvRQTbDd4",
        "outputId": "8d7f338f-d582-4788-c8c2-5bb1748c2855"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 32245 entries, 0 to 33724\n",
            "Data columns (total 7 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   YEAR       32245 non-null  int64 \n",
            " 1   TITLE      32245 non-null  object\n",
            " 2   ABSTRACT   32245 non-null  object\n",
            " 3   AUTHOR     32245 non-null  object\n",
            " 4   PUBLISHER  32245 non-null  object\n",
            " 5   BOOKTITLE  32245 non-null  object\n",
            " 6   CATEGORY   32245 non-null  object\n",
            "dtypes: int64(1), object(6)\n",
            "memory usage: 2.0+ MB\n"
          ]
        }
      ],
      "source": [
        "# FILTRO TODOS LOS REGISTROS CON NULOS, DADO Q SOLO SE PIERDE EL 2.5% DE LOS DATOS.\n",
        "# Y QUIZAS SEA NECESARIO TENER TODOS LOS CAMPOS DE INFO PARA ANALIZAR TOPICOS O GENEROS (SEXO) SEGUN AUTOR, PUBLISHER, ETC\n",
        "data_original = data #GUARDO LA DATA ORIGINAL ANTES DE QUITARLE LOS N/A, POR LAS DUDAS, PARA COMPARAR RESULTADOS\n",
        "data = data.dropna()\n",
        "data.info()\n",
        "#32245/33811 = se perdieron el 4,63% de los datos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCrj2z2e_m3M",
        "outputId": "aefeec2b-5adb-45a0-87df-067013218b3e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Proceedings of the 12th Language Resources and Evaluation Conference                                                      895\n",
              "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing                                    847\n",
              "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics                                   778\n",
              "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)                            751\n",
              "Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)                        745\n",
              "                                                                                                                         ... \n",
              "Actes de la 9{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Conf{\\'e}rences invit{\\'e}es      1\n",
              "Linguistic Issues in Language Technology, Volume 16, 2018                                                                   1\n",
              "Actes de la 18e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Conf{\\'e}rences invit{\\'e}es           1\n",
              "Actes de la 13{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Tutoriels                        1\n",
              "Proceedings of the Workshop on Multilingual Multimodal Learning                                                             1\n",
              "Name: BOOKTITLE, Length: 745, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.BOOKTITLE.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21qRdNxf_m3M",
        "outputId": "f7ba5958-002d-46c1-af32-4eb35c440ae1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Association for Computational Linguistics                                                 20975\n",
              "European Language Resources Association (ELRA)                                             4147\n",
              "ATALA                                                                                      1337\n",
              "European Language Resources Association                                                    1104\n",
              "The COLING 2016 Organizing Committee                                                        738\n",
              "International Committee on Computational Linguistics                                        654\n",
              "INCOMA Ltd.                                                                                 569\n",
              "Association for Machine Translation in the Americas                                         384\n",
              "International Committee for Computational Linguistics                                       307\n",
              "Asian Federation of Natural Language Processing                                             253\n",
              "Chinese Information Processing Society of China                                             217\n",
              "Global Wordnet Association                                                                  200\n",
              "AFCP - ATALA                                                                                169\n",
              "ATALA et AFCP                                                                               160\n",
              "Springer                                                                                    145\n",
              "European Association for Machine Translation                                                140\n",
              "NLP Association of India (NLPAI)                                                            107\n",
              "Australasian Language Technology Association                                                 60\n",
              "Link{\\\"o}ping University Electronic Press                                                    56\n",
              "Link{\\\"o}ping University Electronic Press, Sweden                                            54\n",
              "European Language Resources association                                                      52\n",
              "The Association for Computational Linguistics and Chinese Language Processing (ACLCLP)       51\n",
              "CSLI Publications                                                                            49\n",
              "International Committee on Computational Linguistics (ICCL)                                  48\n",
              "International Workshop on Spoken Language Translation                                        46\n",
              "COLING                                                                                       36\n",
              "NLP Association of India                                                                     28\n",
              "International Conference on Spoken Language Translation                                      28\n",
              "Carnegy Mellon University                                                                    28\n",
              "European Language Resource Association                                                       18\n",
              "Incoma Ltd., Shoumen, Bulgaria                                                               18\n",
              "INCOMA Inc.                                                                                  15\n",
              "Springer Berlin Heidelberg                                                                   15\n",
              "The Association for Machine Translation in the Americas                                      13\n",
              "European Language Ressources Association                                                      9\n",
              "Association for Computational Linguistics, Shoumen, Bulgaria                                  8\n",
              "The European Language Resources Association (ELRA)                                            7\n",
              "Name: PUBLISHER, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.PUBLISHER.value_counts()\n",
        "#20975/21004 = se perdieron el 0,14% de los datos del Publisher \"Association for Computational Linguistics\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb1hnCi0_m3N",
        "outputId": "80dabda6-09ec-49e9-8e60-2a41c42b5661"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "INPROCEEDINGS    32245\n",
              "Name: CATEGORY, dtype: int64"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.CATEGORY.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyopS8PS_m3O",
        "outputId": "db3c02a2-b0c3-4e56-ab5b-58c7f229f40d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Text Worlds are virtual environments for embodied agents that, unlike 2D or 3D environments, are rendered exclusively using textual descriptions. These environments offer an alternative to higher-fidelity 3D environments due to their low barrier to entry, providing the ability to study semantics, compositional inference, and other high-level tasks with rich action spaces while controlling for perceptual input. This systematic survey outlines recent developments in tooling, environments, and agent modeling for Text Worlds, while examining recent trends in knowledge graphs, common sense reasoning, transfer learning of Text World performance to higher-fidelity environments, as well as near-term development targets that, once achieved, make Text Worlds an attractive general research paradigm for natural language processing.',\n",
              "       \"A prototype system for playing a minimal improvisational game with one or more human or computer players is discussed. The game, Chain Reaction, has players collectively build a chain of word pairs or solid compounds. With a basis in oral culture, it emphasizes memory and rapid improvisation. Chains are only locally coherent, so absurdity and humor increases during play. While it is trivial to develop a computer player using textual corpora and literature-culture concepts, our approach is unique in that we have grounded our work in the principles of oral culture according to Walter Ong, an early scholar of orature. We show how a simple computer model can be designed to embody many aspects of oral poetics as theorized by Ong, suggesting design directions for other work in oral improvisation and poetics. The opportunities for own our system{'}s further development include creating culturally specific automated players and situating play in different temporal, physical, and social contexts.\",\n",
              "       \"Non-Player Characters (NPCs) significantly enhance the player experience in many games. Historically, players{'} interactions with NPCs have tended to be highly scripted, to be limited to natural language responses to be selected by the player, and to not involve dynamic change in game state. In this work, we demonstrate that use of a few example conversational prompts can power a conversational agent to generate both natural language and novel code. This approach can permit development of NPCs with which players can have grounded conversations that are free-form and less repetitive. We demonstrate our approach using OpenAI Codex (GPT-3 finetuned on GitHub), with Minecraft game development as our test bed. We show that with a few example prompts, a Codex-based agent can generate novel code, hold multi-turn conversations and answer questions about structured data. We evaluate this application using experienced gamers in a Minecraft realm and provide analysis of failure cases and suggest possible directions for solutions.\"],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#print(data.ABSTRACT[:3])\n",
        "data.ABSTRACT[:3].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "52jsYvY0_m3P",
        "outputId": "b7ac33ad-dcfc-4d8a-caab-4db653b958d5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Non Player Characters NPCs significantly enhance the player experience in many games Historically players interactions with NPCs have tended to be highly scripted to be limited to natural language responses to be selected by the player and to not involve dynamic change in game state In this work we demonstrate that use of a few example conversational prompts can power a conversational agent to generate both natural language and novel code This approach can permit development of NPCs with which players can have grounded conversations that are free form and less repetitive We demonstrate our approach using OpenAI Codex GPT 3 finetuned on GitHub with Minecraft game development as our test bed We show that with a few example prompts a Codex based agent can generate novel code hold multi turn conversations and answer questions about structured data We evaluate this application using experienced gamers in a Minecraft realm and provide analysis of failure cases and suggest possible directions for solutions '"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#\\W: Matchea caracteres que NO sean alfanuméricos; equivalente a[^a-zA-Z0-9_].\n",
        "#Los caracteres especiales + y * machean el patron mas largo posible ( se dice que + y * son \"greedy\")\n",
        "re.sub('[^A-Za-z0-9]+', ' ', data.ABSTRACT[2])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuHKl5h6_m3Q"
      },
      "source": [
        "## Limpieza, Normalizacion y Tokenización."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-Gmt9VqQVU-"
      },
      "outputs": [],
      "source": [
        "## DEFINIMOS FUNCIONES DE LIMPIEZA Y DE TOKENIZACION:\n",
        "# The isinstance() function returns True if the specified object is of the specified type, otherwise False.\n",
        "# \\W: Matchea caracteres que NO sean alfanuméricos; equivalente a[^a-zA-Z0-9_].\n",
        "# \\d: Matchea digitos; equivalente a [0-9]\n",
        "# \"+\": Matchea 1 o mas ocurrencias\n",
        "\n",
        "def clean_text(text):\n",
        "    #Para poder aplicarlo a todo el corpus (lista) #(data.ABSTRACT[0:10]):\n",
        "    if isinstance(text, pd.Series):     \n",
        "        # return text.str.replace('[^A-Za-z0-9]+', ' ', regex = True).str.lower().str.strip().values\n",
        "        return text.str.replace('\\W+', ' ', regex = True).str.lower().str.strip().str.replace('\\d+', '').values\n",
        "    \n",
        "    #Para poder aplicarlo a 1 texto en particular (str) #(data.ABSTRACT[0]):\n",
        "    elif isinstance(text, str):         \n",
        "        return re.sub('\\d+', '',  re.sub('[^A-Za-z0-9]+', ' ' , text.lower()).strip())\n",
        "\n",
        "def tokenizer(text):\n",
        "    #return [w for w in word_tokenize(text) if w.isalpha()] # si solo nos interesan palabras\n",
        "    return word_tokenize(str(text))  ###***OJO: ESTA TOKENIZANDO TODO UN GRAN TEXTO PLANO (LA LISTA DE TEXTOS LA TRANSFORMO EN 1 SOLO TEXTO GIGANTE) \n",
        "    \n",
        "    # if isinstance(text, str):\n",
        "    #     return word_tokenize(text)\n",
        "    # else:\n",
        "    #     return text.apply(word_tokenize)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "T7pyZUwo4YVO",
        "outputId": "9adee2bc-bf43-4e6a-e3cf-1236c4643135"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0        Text Worlds are virtual environments for embod...\\n1        A prototype system for playing a minimal impro...\\n2        Non-Player Characters (NPCs) significantly enh...\\n3        Interactive Question Answering (IQA) requires ...\\n4        The purpose of this extended abstract is to di...\\n                               ...                        \\n33717    There are a number of collocational constraint...\\n33718    The search for efficient parsing strategies ha...\\n33719    PREMO is a knowledge-based Preference Semantic...\\n33720    2-Dimensional Context-Free Grammar (2D-CFG) fo...\\n33724    A parser is described here based on the Cocke-...\\nName: ABSTRACT, Length: 32245, dtype: object'"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(str(data.ABSTRACT))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmufaUKU_m3R",
        "outputId": "06cd87e9-ac87-43eb-8acd-18d6f9aecd2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_text(data.ABSTRACT[0])\n",
        "#type(data.ABSTRACT[0:10])  #pandas.core.series.Series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfF4USkQu2i_",
        "outputId": "054c9bd4-6149-4578-c841-f5587ef2a091"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0        text worlds are virtual environments for embod...\n",
              "1        a prototype system for playing a minimal impro...\n",
              "2        non player characters npcs significantly enhan...\n",
              "3        interactive question answering iqa requires an...\n",
              "4        the purpose of this extended abstract is to di...\n",
              "                               ...                        \n",
              "33717    there are a number of collocational constraint...\n",
              "33718    the search for efficient parsing strategies ha...\n",
              "33719    premo is a knowledge based preference semantic...\n",
              "33720     dimensional context free grammar d cfg for  d...\n",
              "33724    a parser is described here based on the cocke ...\n",
              "Name: ABSTRACT_CL, Length: 32245, dtype: object"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#### APLICAMOS LA FUNCION DE LIMPIEZA A TODO EL CORPUS, SOLO A LOS ABSTRACTS:\n",
        "# EL PROBLEMA ES: *COMO GUARDAR EL TRACKEO DE A QUE AUTOR, PUBLISHER, YEAR, ETC, ESTABA ASOCIADO CADA ABSTRACT***\n",
        "# ***EN EL CLEAN NO SE PIERDE, PERO SI SE VA A PERDER EN EL TOKENIZADO (PORQ SE DESARMA EN UNA LISTA DE PALABRAS).***\n",
        "# *ENTONCES CREO UN CAMPO NUEVO CON EL ABSTRACT LIMPIADO:\n",
        "data = data.assign(ABSTRACT_CL = clean_text(data.ABSTRACT))\n",
        "#clean_text(data.ABSTRACT)\n",
        "#type(clean_text(data.ABSTRACT))  #numpy.ndarray\n",
        "#print(clean_text(data.ABSTRACT))\n",
        "data.ABSTRACT_CL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "xQGnT2xH2267",
        "outputId": "07359e31-57c6-4c7e-8072-4344b526d7ff"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-754200f5-94ad-427d-98d4-310d25a8a490\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>ABSTRACT</th>\n",
              "      <th>AUTHOR</th>\n",
              "      <th>PUBLISHER</th>\n",
              "      <th>BOOKTITLE</th>\n",
              "      <th>CATEGORY</th>\n",
              "      <th>ABSTRACT_CL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022</td>\n",
              "      <td>A Systematic Survey of Text Worlds as Embodied...</td>\n",
              "      <td>Text Worlds are virtual environments for embod...</td>\n",
              "      <td>Jansen, Peter</td>\n",
              "      <td>Association for Computational Linguistics</td>\n",
              "      <td>Proceedings of the 3rd Wordplay: When Language...</td>\n",
              "      <td>INPROCEEDINGS</td>\n",
              "      <td>text worlds are virtual environments for embod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022</td>\n",
              "      <td>A Minimal Computational Improviser Based on Or...</td>\n",
              "      <td>A prototype system for playing a minimal impro...</td>\n",
              "      <td>Montfort, Nick  and</td>\n",
              "      <td>Association for Computational Linguistics</td>\n",
              "      <td>Proceedings of the 3rd Wordplay: When Language...</td>\n",
              "      <td>INPROCEEDINGS</td>\n",
              "      <td>a prototype system for playing a minimal impro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022</td>\n",
              "      <td>Craft an Iron Sword: Dynamically Generating In...</td>\n",
              "      <td>Non-Player Characters (NPCs) significantly enh...</td>\n",
              "      <td>Volum, Ryan  and</td>\n",
              "      <td>Association for Computational Linguistics</td>\n",
              "      <td>Proceedings of the 3rd Wordplay: When Language...</td>\n",
              "      <td>INPROCEEDINGS</td>\n",
              "      <td>non player characters npcs significantly enhan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022</td>\n",
              "      <td>A Sequence Modelling Approach to Question Answ...</td>\n",
              "      <td>Interactive Question Answering (IQA) requires ...</td>\n",
              "      <td>Furman, Gregory  and</td>\n",
              "      <td>Association for Computational Linguistics</td>\n",
              "      <td>Proceedings of the 3rd Wordplay: When Language...</td>\n",
              "      <td>INPROCEEDINGS</td>\n",
              "      <td>interactive question answering iqa requires an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022</td>\n",
              "      <td>Automatic Exploration of Textual Environments ...</td>\n",
              "      <td>The purpose of this extended abstract is to di...</td>\n",
              "      <td>Teodorescu, Laetitia  and</td>\n",
              "      <td>Association for Computational Linguistics</td>\n",
              "      <td>Proceedings of the 3rd Wordplay: When Language...</td>\n",
              "      <td>INPROCEEDINGS</td>\n",
              "      <td>the purpose of this extended abstract is to di...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-754200f5-94ad-427d-98d4-310d25a8a490')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-754200f5-94ad-427d-98d4-310d25a8a490 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-754200f5-94ad-427d-98d4-310d25a8a490');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   YEAR                                              TITLE  \\\n",
              "0  2022  A Systematic Survey of Text Worlds as Embodied...   \n",
              "1  2022  A Minimal Computational Improviser Based on Or...   \n",
              "2  2022  Craft an Iron Sword: Dynamically Generating In...   \n",
              "3  2022  A Sequence Modelling Approach to Question Answ...   \n",
              "4  2022  Automatic Exploration of Textual Environments ...   \n",
              "\n",
              "                                            ABSTRACT  \\\n",
              "0  Text Worlds are virtual environments for embod...   \n",
              "1  A prototype system for playing a minimal impro...   \n",
              "2  Non-Player Characters (NPCs) significantly enh...   \n",
              "3  Interactive Question Answering (IQA) requires ...   \n",
              "4  The purpose of this extended abstract is to di...   \n",
              "\n",
              "                      AUTHOR                                  PUBLISHER  \\\n",
              "0              Jansen, Peter  Association for Computational Linguistics   \n",
              "1        Montfort, Nick  and  Association for Computational Linguistics   \n",
              "2           Volum, Ryan  and  Association for Computational Linguistics   \n",
              "3       Furman, Gregory  and  Association for Computational Linguistics   \n",
              "4  Teodorescu, Laetitia  and  Association for Computational Linguistics   \n",
              "\n",
              "                                           BOOKTITLE       CATEGORY  \\\n",
              "0  Proceedings of the 3rd Wordplay: When Language...  INPROCEEDINGS   \n",
              "1  Proceedings of the 3rd Wordplay: When Language...  INPROCEEDINGS   \n",
              "2  Proceedings of the 3rd Wordplay: When Language...  INPROCEEDINGS   \n",
              "3  Proceedings of the 3rd Wordplay: When Language...  INPROCEEDINGS   \n",
              "4  Proceedings of the 3rd Wordplay: When Language...  INPROCEEDINGS   \n",
              "\n",
              "                                         ABSTRACT_CL  \n",
              "0  text worlds are virtual environments for embod...  \n",
              "1  a prototype system for playing a minimal impro...  \n",
              "2  non player characters npcs significantly enhan...  \n",
              "3  interactive question answering iqa requires an...  \n",
              "4  the purpose of this extended abstract is to di...  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#data.ABSTRACT_CL\n",
        "data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaMFQwFx_m3S",
        "outputId": "3c4dbff2-ab55-41e3-a287-ec065e0af196"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "106"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# word_tokenize(clean_text(data.ABSTRACT))\n",
        "len(tokenizer(data.ABSTRACT_CL))  #106 (!!!!)\n",
        "#type(tokenizer(clean_text(data.ABSTRACT)))  #list\n",
        "#tokenizer(data.ABSTRACT_CL)[:5]  # ['0', 'text', 'worlds', 'are', 'virtual']\n",
        "#tokenizer(clean_text(data.ABSTRACT))[:5]  # ['[', \"'text\", 'worlds', 'are', 'virtual']\n",
        "#tokenizer(data.ABSTRACT_CL)[105]  # ['32245', ',', 'dtype', ':', 'object']\n",
        "#tokenizer(clean_text(data.ABSTRACT))[105]  # ['to', 'parsing', 'time', \"'\", ']']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whUNQ08I_m3T",
        "outputId": "df83d13b-8821-4657-90f8-cf4b051b0f79"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "769"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tokenizer(clean_text(data.ABSTRACT)))\n",
        "#1299   #769 (!!!!!)\n",
        "### XXX NO ENTIENDO PORQUE HACIENDOLO ASI DA 769 TOKENS, Y CON LA COLUMNA NVA \"ABSTRACT.CL\" DA SOLO 106 TOKENS XXX !!!****\n",
        "# ADEMAS, CUANDO LE QUITAS LOS NULOS, DA SOLO #769 (ANTES DABA 1299)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1C4sybMg_m3T",
        "outputId": "d876be38-5cf7-472a-91bb-2ec12d6a4378"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'str'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "#print( type( clean_text( data.ABSTRACT[0]) ))\n",
        "#print( type(clean_text( data.ABSTRACT[:1]) ) )\n",
        "#print( type(clean_text( data.ABSTRACT) ) )\n",
        "\n",
        "# tokenizer(clean_text(data.ABSTRACT[:1] ))#[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucPYuMJ8_ytz",
        "outputId": "c8ec9eeb-d358-4fd2-d219-6917a027ea0f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['[',\n",
              " \"'text\",\n",
              " 'worlds',\n",
              " 'are',\n",
              " 'virtual',\n",
              " 'environments',\n",
              " 'for',\n",
              " 'embodied',\n",
              " 'agents',\n",
              " 'that']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### POR ALGUNA RAZON, AL PASARLO A OTRO CAMPO NUEVO \"ABSTRACT.CL\" NO HACE BIEN EL TOKENIZADO (DEJA SOLO 106 TOKENS, Y TOMA \"array\", \"object\", etc)\n",
        "### ASI Q VUELVO A LA MANERA ORIGINAL DE HACERLO TODO JUNTO EN EL CAMPO \"ABSTRACT\"\n",
        "### CREO UNA VARIABLE Q CONTENGA TODO TOKENIZADO:\n",
        "data_abstracts_token = tokenizer(clean_text(data.ABSTRACT))\n",
        "data_abstracts_token[:10]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHZp3u6EJd0Q",
        "outputId": "34691322-2d10-4243-f964-501696fc08d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "769\n",
            "<class 'list'>\n",
            "['[', \"'text\", 'worlds', 'are', 'virtual', 'environments', 'for', 'embodied', 'agents', 'that', 'unlike', 'd', 'or', 'd', 'environments']\n",
            "['is', 'generated', 'during', 'compilation', 'stage', 'its', 'generation', 'does', 'not', 'add', 'to', 'parsing', 'time', \"'\", ']']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['to', 'be', 'broken', 'into', 'two', 'or', 'more', 'sentences', 'when', 'translating', 'into', 'language', 'a', \"'\", ']']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1182"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(len(data_abstracts_token)) #769: datos sin nulos\n",
        "print(type(data_abstracts_token))\n",
        "print(data_abstracts_token[:15])\n",
        "print(data_abstracts_token[-15:])\n",
        "print(tokenizer(clean_text(data_original.ABSTRACT))[-15:])\n",
        "len((tokenizer(clean_text(data_original.ABSTRACT)))) #1182: datos totales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azBUccys9Ae6"
      },
      "outputs": [],
      "source": [
        "#### CAMBIE EL ORDEN: PRIMERO STOPWORDS Y AL FINAL LEMATIZACION:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QVlUA3I_m3V"
      },
      "source": [
        "## Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6s0ohLP_m3V",
        "outputId": "7d71f459-075d-488d-b675-1e4523dec003"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stoplist = stopwords.words(\"english\")\n",
        "stoplist[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kpa8UvnQ_m3W",
        "outputId": "306ba26a-a31f-4c17-af32-fd3690635106"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ourselves',\n",
              " 'most',\n",
              " 'into',\n",
              " 'through',\n",
              " 'aren',\n",
              " 'who',\n",
              " \"'ve\",\n",
              " 'him',\n",
              " 'have',\n",
              " 'up']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# tokenizo el stoplist con el mismo tokenizar que voy a usar en el corpus\n",
        "stoplist_tokenized = []\n",
        "for w in stoplist:\n",
        "    stoplist_tokenized = stoplist_tokenized + tokenizer(w)\n",
        "    \n",
        "# Armo una lista sin repeticiones\n",
        "stoplist_tokenized = list(set(stoplist_tokenized))\n",
        "\n",
        "stoplist_tokenized[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sga8KKfs_m3T"
      },
      "source": [
        "## Stemming: XXXX NO SE PARA Q SE HACE SI DEPS NO SE USA PARA LA MATRIZ DEL CountVector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4COKf5q__m3U",
        "outputId": "4be548cb-b254-4814-e44c-9c668cadbfab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('worlds', 'world'),\n",
              " ('are', 'are'),\n",
              " ('virtual', 'virtual'),\n",
              " ('environments', 'environ'),\n",
              " ('for', 'for'),\n",
              " ('embodied', 'embodi'),\n",
              " ('agents', 'agent'),\n",
              " ('that', 'that'),\n",
              " ('unlike', 'unlik'),\n",
              " ('d', 'd')]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "\n",
        "[(w,stemmer.stem(w)) for w in tokenizer(clean_text(data.ABSTRACT)) if w.isalpha()][:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzki9MaRpEoD",
        "outputId": "76ae3c48-85e2-47e3-c77e-2aa59416266f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('worlds', 'world'),\n",
              " ('are', 'are'),\n",
              " ('virtual', 'virtual'),\n",
              " ('environments', 'environ'),\n",
              " ('for', 'for'),\n",
              " ('embodied', 'embodi'),\n",
              " ('agents', 'agent'),\n",
              " ('that', 'that'),\n",
              " ('unlike', 'unlik'),\n",
              " ('d', 'd')]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[(w,stemmer.stem(w)) for w in data_abstracts_token if w.isalpha()][:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZfzlmO3paQ4",
        "outputId": "c14f67fc-d117-4c52-f8d8-342473cdf668"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('worlds', 'world'),\n",
              " ('are', 'are'),\n",
              " ('virtual', 'virtual'),\n",
              " ('environments', 'environ'),\n",
              " ('for', 'for'),\n",
              " ('embodied', 'embodi'),\n",
              " ('agents', 'agent'),\n",
              " ('that', 'that'),\n",
              " ('unlike', 'unlik'),\n",
              " ('d', 'd')]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[(w,stemmer.stem(w)) for w in tokenizer(clean_text(data_original.ABSTRACT)) if w.isalpha()][:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vysIRW1Ipk3x",
        "outputId": "e3527abf-9f24-4f7c-a3dc-39aa7e2bdda7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('compilation', 'compil'),\n",
              " ('stage', 'stage'),\n",
              " ('its', 'it'),\n",
              " ('generation', 'generat'),\n",
              " ('does', 'doe'),\n",
              " ('not', 'not'),\n",
              " ('add', 'add'),\n",
              " ('to', 'to'),\n",
              " ('parsing', 'pars'),\n",
              " ('time', 'time')]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[(w,stemmer.stem(w)) for w in data_abstracts_token if w.isalpha()][-10:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZXdC5Rzpsr4",
        "outputId": "8b4fa967-347e-4b1e-d6b1-a59bc24feef2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('into', 'into'),\n",
              " ('two', 'two'),\n",
              " ('or', 'or'),\n",
              " ('more', 'more'),\n",
              " ('sentences', 'sentenc'),\n",
              " ('when', 'when'),\n",
              " ('translating', 'translat'),\n",
              " ('into', 'into'),\n",
              " ('language', 'languag'),\n",
              " ('a', 'a')]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[(w,stemmer.stem(w)) for w in tokenizer(clean_text(data_original.ABSTRACT)) if w.isalpha()][-10:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "OpOuzDdp_m3U",
        "outputId": "37a9edd8-d67a-4e6e-a23a-ec7afc30e388"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'a prototype system for playing a minimal improvisational game with one or more human or computer players is discussed the game chain reaction has players collectively build a chain of word pairs or solid compounds with a basis in oral culture it emphasizes memory and rapid improvisation chains are only locally coherent so absurdity and humor increases during play while it is trivial to develop a computer player using textual corpora and literature culture concepts our approach is unique in that we have grounded our work in the principles of oral culture according to walter ong an early scholar of orature we show how a simple computer model can be designed to embody many aspects of oral poetics as theorized by ong suggesting design directions for other work in oral improvisation and poetics the opportunities for own our system s further development include creating culturally specific automated players and situating play in different temporal physical and social context'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stemmer.stem(clean_text(data.ABSTRACT[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "ISyc848Np9jb",
        "outputId": "cda6d4b7-67b1-4928-e565-fdf73ceb179f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'a prototype system for playing a minimal improvisational game with one or more human or computer players is discussed the game chain reaction has players collectively build a chain of word pairs or solid compounds with a basis in oral culture it emphasizes memory and rapid improvisation chains are only locally coherent so absurdity and humor increases during play while it is trivial to develop a computer player using textual corpora and literature culture concepts our approach is unique in that we have grounded our work in the principles of oral culture according to walter ong an early scholar of orature we show how a simple computer model can be designed to embody many aspects of oral poetics as theorized by ong suggesting design directions for other work in oral improvisation and poetics the opportunities for own our system s further development include creating culturally specific automated players and situating play in different temporal physical and social contexts'"
            ]
          },
          "execution_count": 149,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_text(data.ABSTRACT[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oc3T2j82_m3W",
        "outputId": "11e48a53-1f46-492f-ec95-31a7cc6737f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('t', 't'),\n",
              " ('e', 'e'),\n",
              " ('x', 'x'),\n",
              " ('t', 't'),\n",
              " ('w', 'w'),\n",
              " ('o', 'o'),\n",
              " ('r', 'r'),\n",
              " ('l', 'l'),\n",
              " ('d', 'd'),\n",
              " ('s', 's')]"
            ]
          },
          "execution_count": 150,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[(w,stemmer.stem(w)) for w in clean_text(data.ABSTRACT.iloc[0]) if w.isalpha()][:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4R56Xw4_m3V",
        "outputId": "45ef49de-23c6-4d0e-a810-ccddb9c3d529"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'text worlds are virtual environments for embodied agents that, unlike 2d or 3d environments, are rendered exclusively using textual descriptions. these environments offer an alternative to higher-fidelity 3d environments due to their low barrier to entry, providing the ability to study semantics, compositional inference, and other high-level tasks with rich action spaces while controlling for perceptual input. this systematic survey outlines recent developments in tooling, environments, and agent modeling for text worlds, while examining recent trends in knowledge graphs, common sense reasoning, transfer learning of text world performance to higher-fidelity environments, as well as near-term development targets that, once achieved, make text worlds an attractive general research paradigm for natural language processing.'"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_text(data.ABSTRACT[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15w4HHLTqcm-"
      },
      "outputs": [],
      "source": [
        "#CREO UNA VARIABLE CON TODO EL TEXTO LIMPIADO, TOKENIZADO Y STEMMIZADO (XXX ESTO ULTIMO NO SE POR QUE NO SE CARGA AL CountVectorizer)\n",
        "#data_abstracts_token[:15]\n",
        "data_abstracts_token_stem = [stemmer.stem(w) for w in data_abstracts_token ] #if w.isalpha()]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIkQPCbgwfrf",
        "outputId": "c15e4503-92b8-4249-d98f-2792e67590ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[',\n",
              " 'text',\n",
              " 'world',\n",
              " 'are',\n",
              " 'virtual',\n",
              " 'environ',\n",
              " 'for',\n",
              " 'embodi',\n",
              " 'agent',\n",
              " 'that',\n",
              " 'unlik',\n",
              " 'd',\n",
              " 'or',\n",
              " 'd',\n",
              " 'environ']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_abstracts_token_stem[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFaM2s1Lw7LV",
        "outputId": "8946c464-c678-4040-e0c8-203d5adbd06a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['is',\n",
              " 'generat',\n",
              " 'dure',\n",
              " 'compil',\n",
              " 'stage',\n",
              " 'it',\n",
              " 'generat',\n",
              " 'doe',\n",
              " 'not',\n",
              " 'add',\n",
              " 'to',\n",
              " 'pars',\n",
              " 'time',\n",
              " \"'\",\n",
              " ']']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_abstracts_token_stem[-15:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXlGYWEWw_MM",
        "outputId": "9e9997dc-d3a8-4fd2-869a-a7fc4a48591e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "769"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data_abstracts_token_stem) #769: ESTOS SON LOS TOKENS STEMIZADOS:\n",
        "# XXX NO SE POR QUE DEPS NO SE USAN PARA EL CountVectorizer !!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNfkHnXF_m3X"
      },
      "source": [
        "## Extraigo features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sh5Za4JD_m3X",
        "outputId": "8f14c8f3-cc73-4e0a-9ba4-4057be597ea0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['n'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<32245x14878 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 2109709 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#### CREO LA FUNCION DEL CountVectorizer, Q CUENTA APARICION DE PALABRAS POR DOCUMENTO, APLICA PREPROCESADO, TOKENIZADO, STOPS Y MIN DE APARICIONES\n",
        "#### LUEGO APLICO fit_transform Q CREARA UNA MATRIZ \"TERMINO-DOCUMENTO\" O \"BOLSA DE PALABRAS\".\n",
        "# The astype(‘U’) is telling numpy to convert the data to Unicode (essentially a string in python 3).\n",
        "\n",
        "count_vect = CountVectorizer(preprocessor=clean_text,\n",
        "                             tokenizer=tokenizer,\n",
        "                             min_df=5,\n",
        "                             stop_words=stoplist_tokenized)\n",
        "\n",
        "data_clean = count_vect.fit_transform(data.ABSTRACT.values.astype('U')) # cuenta frecuencia de tokens y define el diccionario\n",
        "# X_test = count_vect.transform(X_test_text) # cuenta frecuencia de tokens existentes en el diccionario\n",
        "data_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9Z2UircUsL8",
        "outputId": "b1547c67-c4c1-4ac7-e442-26a28bddc7e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<769x12 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 77 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#### VOY A PROBAR CREAR LO MISMO DE ANTES (MATRIZ TERMINO-DOCUMENTO) PERO USANDO LOS TOKENS STEMMIZADOS:\n",
        "data_abstracts_token_stem\n",
        "count_vect_STEM = CountVectorizer(\n",
        "                             min_df=5,\n",
        "                             stop_words=stoplist_tokenized)\n",
        "\n",
        "data_clean_STEM = count_vect_STEM.fit_transform(data_abstracts_token_stem) # cuenta frecuencia de tokens y define el diccionario\n",
        "data_clean_STEM\n",
        "#### XXXXX NO SIRVE PORQ SE OBTIENE UNA MATRIZ DE 769 TOKENS, NO DE 32245 DOCUMENTOS XXXX\n",
        "#<769x12 sparse matrix of type '<class 'numpy.int64'>'\n",
        "#\twith 77 stored elements in Compressed Sparse Row format>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYVnUivv_m3X"
      },
      "source": [
        "+ Consultar sobre diferencia entre fit_transform y transform\n",
        "\n",
        "+ Falta limpiar  terminos ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YC_Bmxdo_m3Y",
        "outputId": "6f74b082-3c99-4400-9d9d-722ca527a4f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tamaño de la matriz: 479741110\n",
            "porcentaje de elementos distintos de cero: % 0.34\n"
          ]
        }
      ],
      "source": [
        "print(\"tamaño de la matriz:\",32245*14878)\n",
        "print(\"porcentaje de elementos distintos de cero: %\",round(100*2109709/(32352*19342),2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAZcLCEm_m3Y",
        "outputId": "4cc4ddb3-585d-4e99-95c0-cae344a970f6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['aa',\n",
              " 'aac',\n",
              " 'aachen',\n",
              " 'aae',\n",
              " 'ab',\n",
              " 'abandoned',\n",
              " 'abbreviated',\n",
              " 'abbreviation',\n",
              " 'abbreviations',\n",
              " 'abc',\n",
              " 'abduction',\n",
              " 'abductive',\n",
              " 'abdul',\n",
              " 'abeill',\n",
              " 'abilities']"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vect.get_feature_names()[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHqBcRSuXo0T",
        "outputId": "bca6ca9d-68b9-433b-ac19-2d02e50cdf0c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['algorithm',\n",
              " 'develop',\n",
              " 'dimension',\n",
              " 'environ',\n",
              " 'game',\n",
              " 'languag',\n",
              " 'pars',\n",
              " 'player',\n",
              " 'prefer',\n",
              " 'rule',\n",
              " 'text',\n",
              " 'use']"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vect_STEM.get_feature_names()[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZMzeYW10ftT",
        "outputId": "c7d69fab-4546-4533-e395-b1f957568658"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CountVectorizer(min_df=5, preprocessor=<function clean_text at 0x7f59c6080cb0>,\n",
              "                stop_words=['ourselves', 'most', 'into', 'through', 'aren',\n",
              "                            'who', \"'ve\", 'him', 'have', 'up', 'its', 'whom',\n",
              "                            'where', 'such', 'at', 'from', 'once', 'no', 'not',\n",
              "                            'which', 'her', 'ain', 'will', 'haven', 'wasn',\n",
              "                            'or', 'against', 'other', 'below', 'did', ...],\n",
              "                tokenizer=<function tokenizer at 0x7f59c6080dd0>)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTJnCoG10tqT",
        "outputId": "4f83363d-597b-472f-dc29-8b30dbe99541"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sklearn.feature_extraction.text.CountVectorizer"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(count_vect)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0bnEVsa08fD",
        "outputId": "ea343f4f-0eb5-4a95-8dbe-e68c1407d2af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "scipy.sparse.csr.csr_matrix"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(data_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "la32ES6O0_f6",
        "outputId": "fba22ba7-2fba-4c6c-a67c-24c5d8e0c2c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<32245x14878 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 2109709 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FNDxSvb1EnV",
        "outputId": "7b60eb74-aa21-478d-c768-474715aa5485"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(32245, 14878)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#print(data_clean[:20])\n",
        "np.shape(data_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noSm0A_z2DiP",
        "outputId": "dea94da2-700c-42be-a13b-cf4004a8aaa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compressed Sparse Row matrix\n",
            "\n",
            "This can be instantiated in several ways:\n",
            "    csr_matrix(D)\n",
            "        with a dense matrix or rank-2 ndarray D\n",
            "\n",
            "    csr_matrix(S)\n",
            "        with another sparse matrix S (equivalent to S.tocsr())\n",
            "\n",
            "    csr_matrix((M, N), [dtype])\n",
            "        to construct an empty matrix with shape (M, N)\n",
            "        dtype is optional, defaulting to dtype='d'.\n",
            "\n",
            "    csr_matrix((data, (row_ind, col_ind)), [shape=(M, N)])\n",
            "        where ``data``, ``row_ind`` and ``col_ind`` satisfy the\n",
            "        relationship ``a[row_ind[k], col_ind[k]] = data[k]``.\n",
            "\n",
            "    csr_matrix((data, indices, indptr), [shape=(M, N)])\n",
            "        is the standard CSR representation where the column indices for\n",
            "        row i are stored in ``indices[indptr[i]:indptr[i+1]]`` and their\n",
            "        corresponding values are stored in ``data[indptr[i]:indptr[i+1]]``.\n",
            "        If the shape parameter is not supplied, the matrix dimensions\n",
            "        are inferred from the index arrays.\n",
            "\n",
            "Attributes\n",
            "----------\n",
            "dtype : dtype\n",
            "    Data type of the matrix\n",
            "shape : 2-tuple\n",
            "    Shape of the matrix\n",
            "ndim : int\n",
            "    Number of dimensions (this is always 2)\n",
            "nnz\n",
            "    Number of stored values, including explicit zeros\n",
            "data\n",
            "    CSR format data array of the matrix\n",
            "indices\n",
            "    CSR format index array of the matrix\n",
            "indptr\n",
            "    CSR format index pointer array of the matrix\n",
            "has_sorted_indices\n",
            "    Whether indices are sorted\n",
            "\n",
            "Notes\n",
            "-----\n",
            "\n",
            "Sparse matrices can be used in arithmetic operations: they support\n",
            "addition, subtraction, multiplication, division, and matrix power.\n",
            "\n",
            "Advantages of the CSR format\n",
            "  - efficient arithmetic operations CSR + CSR, CSR * CSR, etc.\n",
            "  - efficient row slicing\n",
            "  - fast matrix vector products\n",
            "\n",
            "Disadvantages of the CSR format\n",
            "  - slow column slicing operations (consider CSC)\n",
            "  - changes to the sparsity structure are expensive (consider LIL or DOK)\n",
            "\n",
            "Examples\n",
            "--------\n",
            "\n",
            ">>> import numpy as np\n",
            ">>> from scipy.sparse import csr_matrix\n",
            ">>> csr_matrix((3, 4), dtype=np.int8).toarray()\n",
            "array([[0, 0, 0, 0],\n",
            "       [0, 0, 0, 0],\n",
            "       [0, 0, 0, 0]], dtype=int8)\n",
            "\n",
            ">>> row = np.array([0, 0, 1, 2, 2, 2])\n",
            ">>> col = np.array([0, 2, 2, 0, 1, 2])\n",
            ">>> data = np.array([1, 2, 3, 4, 5, 6])\n",
            ">>> csr_matrix((data, (row, col)), shape=(3, 3)).toarray()\n",
            "array([[1, 0, 2],\n",
            "       [0, 0, 3],\n",
            "       [4, 5, 6]])\n",
            "\n",
            ">>> indptr = np.array([0, 2, 3, 6])\n",
            ">>> indices = np.array([0, 2, 2, 0, 1, 2])\n",
            ">>> data = np.array([1, 2, 3, 4, 5, 6])\n",
            ">>> csr_matrix((data, indices, indptr), shape=(3, 3)).toarray()\n",
            "array([[1, 0, 2],\n",
            "       [0, 0, 3],\n",
            "       [4, 5, 6]])\n",
            "\n",
            "Duplicate entries are summed together:\n",
            "\n",
            ">>> row = np.array([0, 1, 2, 0])\n",
            ">>> col = np.array([0, 1, 1, 0])\n",
            ">>> data = np.array([1, 2, 4, 8])\n",
            ">>> csr_matrix((data, (row, col)), shape=(3, 3)).toarray()\n",
            "array([[9, 0, 0],\n",
            "       [0, 2, 0],\n",
            "       [0, 4, 0]])\n",
            "\n",
            "As an example of how to construct a CSR matrix incrementally,\n",
            "the following snippet builds a term-document matrix from texts:\n",
            "\n",
            ">>> docs = [[\"hello\", \"world\", \"hello\"], [\"goodbye\", \"cruel\", \"world\"]]\n",
            ">>> indptr = [0]\n",
            ">>> indices = []\n",
            ">>> data = []\n",
            ">>> vocabulary = {}\n",
            ">>> for d in docs:\n",
            "...     for term in d:\n",
            "...         index = vocabulary.setdefault(term, len(vocabulary))\n",
            "...         indices.append(index)\n",
            "...         data.append(1)\n",
            "...     indptr.append(len(indices))\n",
            "...\n",
            ">>> csr_matrix((data, indices, indptr), dtype=int).toarray()\n",
            "array([[2, 1, 0, 0],\n",
            "       [0, 1, 1, 1]])\n"
          ]
        }
      ],
      "source": [
        "np.info(data_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lv1porhj2WWe",
        "outputId": "2357efb9-2a3a-442f-a6d5-477be50c0e7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 13364)\t4\n",
            "  (0, 14781)\t3\n",
            "  (0, 14467)\t1\n",
            "  (0, 4582)\t6\n",
            "  (0, 4340)\t1\n",
            "  (0, 341)\t1\n",
            "  (0, 14124)\t1\n",
            "  (0, 11210)\t1\n",
            "  (0, 4811)\t1\n",
            "  (0, 14244)\t1\n",
            "  (0, 13380)\t1\n",
            "  (0, 3536)\t1\n",
            "  (0, 9132)\t1\n",
            "  (0, 500)\t1\n",
            "  (0, 6121)\t2\n",
            "  (0, 5187)\t2\n",
            "  (0, 4120)\t1\n",
            "  (0, 7809)\t1\n",
            "  (0, 1227)\t1\n",
            "  (0, 4574)\t1\n",
            "  (0, 10549)\t1\n",
            "  (0, 15)\t1\n",
            "  (0, 12756)\t1\n",
            "  (0, 11929)\t1\n",
            "  (0, 2435)\t1\n",
            "  :\t:\n",
            "  (32244, 729)\t1\n",
            "  (32244, 4028)\t1\n",
            "  (32244, 737)\t1\n",
            "  (32244, 9534)\t1\n",
            "  (32244, 8210)\t3\n",
            "  (32244, 418)\t1\n",
            "  (32244, 13136)\t2\n",
            "  (32244, 9530)\t1\n",
            "  (32244, 11662)\t4\n",
            "  (32244, 2375)\t1\n",
            "  (32244, 13544)\t1\n",
            "  (32244, 8307)\t1\n",
            "  (32244, 8760)\t1\n",
            "  (32244, 4857)\t1\n",
            "  (32244, 7626)\t1\n",
            "  (32244, 11664)\t2\n",
            "  (32244, 6419)\t1\n",
            "  (32244, 2860)\t1\n",
            "  (32244, 6728)\t1\n",
            "  (32244, 4534)\t1\n",
            "  (32244, 14854)\t1\n",
            "  (32244, 7229)\t1\n",
            "  (32244, 10145)\t1\n",
            "  (32244, 1275)\t1\n",
            "  (32244, 2162)\t1\n"
          ]
        }
      ],
      "source": [
        "print(data_clean)  ### HACER LDA!!!!!\n",
        "### (ANTES PROBAR EL data_clean HACERLO STEMMIZADO!!!!!): NO FUNCIONA XXX \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp2P0f6GYbt5",
        "outputId": "eea5ef3d-eb31-4053-e5b7-cea6058288f5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['n'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(32245, 14878)\n"
          ]
        }
      ],
      "source": [
        "#### LDA TOTAL (SIN FILTRAR POR AÑO):\n",
        "#### 1) HAY QUE HACER LA TRANSFORMACION TF-IDF \n",
        "#(para transformar la Bolsa de Palabras en una Bolsa con Importancia por cada Palabra: aplica una formula con el logaritmo de la cantidad q aparecen en todos los documentos)\n",
        "# https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\n",
        "\n",
        "#### TRANSFORMACION TF-IDF: NO SE SI SE APLICA A LA MATRIZ TERMINO-DOC O AL TEXTO PREVIO EN CRUDO!!!!\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\"\"\"corpus = [     'This is the first document.',\n",
        "     'This document is the second document.',\n",
        "     'And this is the third one.',\n",
        "     'Is this the first document?',\n",
        " ]\"\"\"\n",
        "# corpus = data_clean  ### FALLA: POR LO TANTO SE APLICA AL TEXTO CRUDO.\n",
        "\n",
        "#vectorizer = TfidfVectorizer()\n",
        "#X = vectorizer.fit_transform(corpus)\n",
        "#vectorizer.get_feature_names_out()\n",
        "\n",
        "#print(X.shape)\n",
        "\n",
        "vectorizer = TfidfVectorizer(preprocessor=clean_text,\n",
        "                             tokenizer=tokenizer,\n",
        "                             min_df=5,\n",
        "                             stop_words=stoplist_tokenized)\n",
        "\n",
        "data_TF_IDF = vectorizer.fit_transform(data.ABSTRACT.values.astype('U')) # cuenta frecuencia de tokens y define el diccionario\n",
        "vectorizer.get_feature_names_out()\n",
        "\n",
        "print(data_TF_IDF.shape)\n",
        "\"\"\"usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['n'] not in stop_words.\n",
        "  % sorted(inconsistent)\n",
        "(32245, 14878)\"\"\"\n",
        "# FUNCIONO!: GENERO UNA MATRIZ DE 32245 X 14878 (IGUAL TAMAÑO Q LA TERMINO-DOC!)\n",
        "#data_clean\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JhBOVZHf2qN",
        "outputId": "d26eef15-5ccd-4606-c5e6-c5440fd43f21"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<32245x14878 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 2109709 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_TF_IDF\n",
        "\"\"\"<32245x14878 sparse matrix of type '<class 'numpy.float64'>'\n",
        "\twith 2109709 stored elements in Compressed Sparse Row format>\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGmNq_UCgFvs",
        "outputId": "4d7f9dc7-57cb-4e78-d3f5-e4aaeff4df41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['aa', 'aac', 'aachen', ..., 'zsl', 'zulu', 'zurich'], dtype=object)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorizer.get_feature_names_out()\n",
        "# array(['aa', 'aac', 'aachen', ..., 'zsl', 'zulu', 'zurich'], dtype=object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "A7ypqHyZgP2D",
        "outputId": "9bf58e4d-7099-403b-bd9d-1d6b3a58bf5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'array([[0.00360392, 0.25499205, 0.0036211 , 0.64236448, 0.09541846],\\n       [0.15297572, 0.00362644, 0.44412786, 0.39568399, 0.003586  ]])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "# 2) AHORA SI PUEDO HACER EL LDA, APLICADO AL TF-IDF GENERADO ANTERIORMENTE:\n",
        "\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.datasets import make_multilabel_classification\n",
        "# This produces a feature matrix of token counts, similar to what\n",
        "# CountVectorizer would produce on text.\n",
        "\n",
        "#X, _ = make_multilabel_classification(random_state=0)\n",
        "X = data_TF_IDF  # LE DOY PARA Q COMA EL TF-IDF Q GENERAMOS ANTES\n",
        "\n",
        "lda = LatentDirichletAllocation(n_components=10,\n",
        "     random_state=0)\n",
        "\n",
        "lda.fit(X)\n",
        "\"\"\"LatentDirichletAllocation(...)\"\"\"\n",
        " \n",
        " # get topics for some given samples:\n",
        "lda.transform(X[-2:])\n",
        "\"\"\"array([[0.00360392, 0.25499205, 0.0036211 , 0.64236448, 0.09541846],\n",
        "       [0.15297572, 0.00362644, 0.44412786, 0.39568399, 0.003586  ]])\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ah0zug4OjmOc"
      },
      "outputs": [],
      "source": [
        "#lda.print_topics(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MAhK_EjjJJ8"
      },
      "outputs": [],
      "source": [
        "### AHORA INTENTARE DIVISAR ALGUNOS TOPICOS CREADOS:\n",
        "#lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
        "#for idx, topic in lda.print_topics(-1):\n",
        " #   print('Topic: {} Word: {}'.format(idx, topic))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kKU2XFkP0oRY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}