{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df02a7c-d592-4511-aba0-0833e10e2927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mateo1/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/mateo1/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot  as plt\n",
    "\n",
    "\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b339420-6159-48aa-bf1a-2db31994be78",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d59369ca-9200-4d07-b472-b1471936b206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>PUBLISHER</th>\n",
       "      <th>BOOKTITLE</th>\n",
       "      <th>CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1963</td>\n",
       "      <td>On the order of clauses</td>\n",
       "      <td>We used to think that the output of a translat...</td>\n",
       "      <td>Yngve, Victor H.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Proceedings of the Annual meeting of the Assoc...</td>\n",
       "      <td>INPROCEEDINGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1963</td>\n",
       "      <td>Connectability calculations, syntactic functio...</td>\n",
       "      <td>A program for sentence-structure determination...</td>\n",
       "      <td>Hays, David G.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Proceedings of the Annual meeting of the Assoc...</td>\n",
       "      <td>INPROCEEDINGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1963</td>\n",
       "      <td>A study of the combinatorial properties of {R}...</td>\n",
       "      <td>A statistical study was made of the extent to ...</td>\n",
       "      <td>Harper, Kenneth E.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Proceedings of the Annual meeting of the Assoc...</td>\n",
       "      <td>INPROCEEDINGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1963</td>\n",
       "      <td>Word and context association by means of linea...</td>\n",
       "      <td>This paper is concerned with the use of electr...</td>\n",
       "      <td>Giuliano, Vincent E.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Proceedings of the Annual meeting of the Assoc...</td>\n",
       "      <td>INPROCEEDINGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1963</td>\n",
       "      <td>La traduction automatique et l{'}enseignement ...</td>\n",
       "      <td>Les recherches effectuées depuis quelques ann...</td>\n",
       "      <td>Gentilhomme, Yves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Proceedings of the Annual meeting of the Assoc...</td>\n",
       "      <td>INPROCEEDINGS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR                                              TITLE  \\\n",
       "0  1963                            On the order of clauses   \n",
       "1  1963  Connectability calculations, syntactic functio...   \n",
       "2  1963  A study of the combinatorial properties of {R}...   \n",
       "3  1963  Word and context association by means of linea...   \n",
       "4  1963  La traduction automatique et l{'}enseignement ...   \n",
       "\n",
       "                                            ABSTRACT                AUTHOR  \\\n",
       "0  We used to think that the output of a translat...      Yngve, Victor H.   \n",
       "1  A program for sentence-structure determination...        Hays, David G.   \n",
       "2  A statistical study was made of the extent to ...    Harper, Kenneth E.   \n",
       "3  This paper is concerned with the use of electr...  Giuliano, Vincent E.   \n",
       "4  Les recherches effectuées depuis quelques ann...     Gentilhomme, Yves   \n",
       "\n",
       "  PUBLISHER                                          BOOKTITLE       CATEGORY  \n",
       "0       NaN  Proceedings of the Annual meeting of the Assoc...  INPROCEEDINGS  \n",
       "1       NaN  Proceedings of the Annual meeting of the Assoc...  INPROCEEDINGS  \n",
       "2       NaN  Proceedings of the Annual meeting of the Assoc...  INPROCEEDINGS  \n",
       "3       NaN  Proceedings of the Annual meeting of the Assoc...  INPROCEEDINGS  \n",
       "4       NaN  Proceedings of the Annual meeting of the Assoc...  INPROCEEDINGS  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/data_sample.csv\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2a3803-4efd-4ac9-aae5-62daba15f9ab",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfe6edca-05c6-4a40-9c4a-7a22e8d75684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1817"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anio_corte = 2016\n",
    "\n",
    "len(data[data['YEAR']==anio_corte])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f167765-8d99-42de-8cb1-33a2d61ba445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022    0.097332\n",
       "2021    0.097332\n",
       "2020    0.097332\n",
       "2019    0.097332\n",
       "2018    0.097332\n",
       "2017    0.097332\n",
       "2016    0.097332\n",
       "2014    0.048264\n",
       "2010    0.045747\n",
       "2012    0.043122\n",
       "2008    0.040872\n",
       "2006    0.033962\n",
       "2004    0.010767\n",
       "2005    0.009749\n",
       "2003    0.009428\n",
       "2011    0.008839\n",
       "2001    0.008464\n",
       "2015    0.007982\n",
       "2009    0.007446\n",
       "2007    0.006160\n",
       "2002    0.004714\n",
       "1999    0.004339\n",
       "2013    0.004232\n",
       "2000    0.004232\n",
       "1997    0.003375\n",
       "1998    0.002732\n",
       "1989    0.002518\n",
       "1991    0.002411\n",
       "1993    0.002303\n",
       "1963    0.001821\n",
       "1995    0.001768\n",
       "1994    0.000643\n",
       "1984    0.000643\n",
       "1977    0.000589\n",
       "1976    0.000536\n",
       "1975    0.000375\n",
       "1978    0.000321\n",
       "1974    0.000268\n",
       "1971    0.000054\n",
       "Name: YEAR, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_sample = len(data[data['YEAR']==anio_corte])\n",
    "semilla = 420\n",
    "\n",
    "data_original = data.copy() \n",
    "\n",
    "data_sample = data[data['YEAR']<anio_corte].sort_values('YEAR', ascending =True)\n",
    "data_sample\n",
    "\n",
    "for i in range(2016, 2023):\n",
    "    data_i = data[data['YEAR']== i].sample(paper_sample, random_state= semilla) \n",
    "    \n",
    "    data_sample = pd.concat([data_sample, data_i])\n",
    "\n",
    "\n",
    "data_sample.to_csv('data/data_sample.csv', index = False)\n",
    "data_sample.YEAR.value_counts(normalize = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "851154de-e9af-463e-bc9a-9e134fa5d024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We used to think that the output of a translation machine would be stylistically inelegant, but this would be tolerable if only the message got across. We now find that getting the message across accurately is difficult, but we may be able to have stylistic elegance in the output since much of style reflects depth phenomena and thus is systematic. As an example, the order of the clauses in many twoclause sentences can be reversed without a change of meaning, but the same is not normally true of sentences with more than two clauses. The meaning usually changes when the clause order is changed. Equivalently, there appear to be severe restrictions on clause order for any given meaning. These restrictions appear to follow from depth considerations. The idea is being investigated that there is a normal depth-related clause order and any deviations from this order must be signalled by special syntactic or semantic devices. The nature of these devices is being explored. When translating multi-clause sentences, there may be trouble due to the fact that the clause types of the two languages are not exactly parallel. Therefore the list of allowed and preferred clause orders in the two languages will not be equivalent and the special syntactic and semantic devices available to signal deviations from the normal order will be different. Thus one would predict that multi-clause sentences in language A often have to be split into two or more sentences when translated into language B, while at the same time multi-clause sentences in language B will often have to be broken into two or more sentences when translating into language A.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = data_sample.ABSTRACT.tolist()\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d4fbcd-3e18-4da8-8e18-a7afb5859a53",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdcc2877-24be-4b95-815c-4c0e6662af73",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = stopwords.words(\"english\")\n",
    "\n",
    "def tokenize(x):\n",
    "    return [word for word in word_tokenize(x) if word not in STOP_WORDS and word.isalpha() and len(word)>1]\n",
    "    \n",
    "texts= [tokenize(str(doc).lower()) for doc in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a44eb83-422a-44c9-9631-d22fa69df679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>used think output translation machine would st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>approach study information processing verbal i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>establishing grammatical description language ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>becomes evident successful pragmatics automati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>exhaustive syntactic analysis using predictive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18663</th>\n",
       "      <td>algorithmic oppression urgent persistent probl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18664</th>\n",
       "      <td>little attention paid early rumor detection ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18665</th>\n",
       "      <td>report generate synthetic error dataset swedis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18666</th>\n",
       "      <td>recent improvements automatic news summarizati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18667</th>\n",
       "      <td>paper set quantify syntactic capacity bert eva...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18668 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0      used think output translation machine would st...\n",
       "1      approach study information processing verbal i...\n",
       "2      establishing grammatical description language ...\n",
       "3      becomes evident successful pragmatics automati...\n",
       "4      exhaustive syntactic analysis using predictive...\n",
       "...                                                  ...\n",
       "18663  algorithmic oppression urgent persistent probl...\n",
       "18664  little attention paid early rumor detection ea...\n",
       "18665  report generate synthetic error dataset swedis...\n",
       "18666  recent improvements automatic news summarizati...\n",
       "18667  paper set quantify syntactic capacity bert eva...\n",
       "\n",
       "[18668 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_df = pd.DataFrame([' '.join(text) for text in texts], columns = ['text'])\n",
    "texts_df.to_csv('data/data_clean.csv', index = False)\n",
    "\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98dc1ca-c028-495d-839e-bf2d5d8a261a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5792438a-ecb1-4c19-8c14-4165136bd482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be66f3a2-8ab8-4b34-b4cd-e89793dc2778",
   "metadata": {},
   "source": [
    "## Word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b3cf278-c313-49bb-939f-923b1a7000f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>language</td>\n",
       "      <td>12867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model</td>\n",
       "      <td>11440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data</td>\n",
       "      <td>10060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de</td>\n",
       "      <td>10043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paper</td>\n",
       "      <td>9723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37077</th>\n",
       "      <td>sultent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37078</th>\n",
       "      <td>jordanien</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37079</th>\n",
       "      <td>coarticulation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37080</th>\n",
       "      <td>anticipatoire</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37081</th>\n",
       "      <td>ctr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37082 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Word  Frequency\n",
       "0            language      12867\n",
       "1               model      11440\n",
       "2                data      10060\n",
       "3                  de      10043\n",
       "4               paper       9723\n",
       "...               ...        ...\n",
       "37077         sultent          1\n",
       "37078       jordanien          1\n",
       "37079  coarticulation          1\n",
       "37080   anticipatoire          1\n",
       "37081             ctr          1\n",
       "\n",
       "[37082 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = texts_df.text.str.split(expand=True).stack().value_counts().reset_index()\n",
    " \n",
    "new_df.columns = ['Word', 'Frequency'] \n",
    " \n",
    "new_df.to_csv('data/word_count.csv', index = False)\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8a6406-0388-410a-8566-1c3a7f17245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot de frecuencia vs ranking (la palabra mas frecuente tiene rank=1, la segunda tiene rank=2, etc..)\n",
    "plt.plot(range(len(new_df)),new_df.Frequency)\n",
    "plt.xlabel('rank');plt.ylabel('freq');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b18237-ed8f-4fb0-92b6-aa4e4d2586e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  # palabras con 1 sola occurrencia\n",
    "print(\"el \",\n",
    "      round(100*sum(new_df.Frequency==1)/len(new_df.Frequency),2),\n",
    "      \"% de las palabras aparecen 1 sola vez\")\n",
    "\n",
    "print(\"las 10 palabras mas frecuentes representan el \",\n",
    "      round(100*new_df.Frequency[:10].sum()/new_df.Frequency.sum(),2),\n",
    "      \"% del corpus\")\n",
    "\n",
    "print(texts[0])\n",
    "\n",
    "'translation' in texts[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
